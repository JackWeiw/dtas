[
    {
        "fused_layer_norm_cast1_<n: Range(1, 128)>": {
            "latency(ms)": 0.0035573331065277478,
            "config": [
                {
                    "len_tx": 256,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(3)):\n                for ax2_1 in T.thread_binding(T.int64(256), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(1024) + ax2_1 * T.int64(4) + ax2_2)\n                            T.where((ax2_0 * T.int64(256) + ax2_1) * T.int64(4) + ax2_2 < T.int64(2560))\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(256), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(10), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(256) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(256), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(10), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(256) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(129, 256)>": {
            "latency(ms)": 0.004707179548187053,
            "config": [
                {
                    "len_tx": 256,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(3)):\n                for ax2_1 in T.thread_binding(T.int64(256), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(1024) + ax2_1 * T.int64(4) + ax2_2)\n                            T.where((ax2_0 * T.int64(256) + ax2_1) * T.int64(4) + ax2_2 < T.int64(2560))\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(256), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(10), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(256) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(256), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(10), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(256) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(257, 384)>": {
            "latency(ms)": 0.005505066609118732,
            "config": [
                {
                    "len_tx": 128,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(5)):\n                for ax2_1 in T.thread_binding(T.int64(128), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(512) + ax2_1 * T.int64(4) + ax2_2)\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(128), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(20), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(128) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(128), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(20), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(128) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(385, 512)>": {
            "latency(ms)": 0.009521924503847711,
            "config": [
                {
                    "len_tx": 320,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(2)):\n                for ax2_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(1280) + ax2_1 * T.int64(4) + ax2_2)\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(8), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(320) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(8), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(320) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(513, 640)>": {
            "latency(ms)": 0.013542605342804197,
            "config": [
                {
                    "len_tx": 320,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(2)):\n                for ax2_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(1280) + ax2_1 * T.int64(4) + ax2_2)\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(8), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(320) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(8), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(320) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(641, 768)>": {
            "latency(ms)": 0.015759856489245352,
            "config": [
                {
                    "len_tx": 320,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(2)):\n                for ax2_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(1280) + ax2_1 * T.int64(4) + ax2_2)\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(8), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(320) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(8), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(320) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(769, 896)>": {
            "latency(ms)": 0.018235069852455408,
            "config": [
                {
                    "len_tx": 320,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(2)):\n                for ax2_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(1280) + ax2_1 * T.int64(4) + ax2_2)\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(8), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(320) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(8), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(320) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(897, 1024)>": {
            "latency(ms)": 0.020312443002915452,
            "config": [
                {
                    "len_tx": 320,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(2)):\n                for ax2_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(1280) + ax2_1 * T.int64(4) + ax2_2)\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(8), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(320) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(8), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(320) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(1025, 1152)>": {
            "latency(ms)": 0.022735879773730684,
            "config": [
                {
                    "len_tx": 320,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(2)):\n                for ax2_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(1280) + ax2_1 * T.int64(4) + ax2_2)\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(8), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(320) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(8), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(320) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(1153, 1280)>": {
            "latency(ms)": 0.02510403858433735,
            "config": [
                {
                    "len_tx": 320,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(2)):\n                for ax2_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(1280) + ax2_1 * T.int64(4) + ax2_2)\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(8), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(320) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(8), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(320) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(1281, 1408)>": {
            "latency(ms)": 0.027460409221516872,
            "config": [
                {
                    "len_tx": 512,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(2)):\n                for ax2_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(2048) + ax2_1 * T.int64(4) + ax2_2)\n                            T.where((ax2_0 * T.int64(512) + ax2_1) * T.int64(4) + ax2_2 < T.int64(2560))\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(512) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(512) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(1409, 1536)>": {
            "latency(ms)": 0.02979556362973761,
            "config": [
                {
                    "len_tx": 512,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(2)):\n                for ax2_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(2048) + ax2_1 * T.int64(4) + ax2_2)\n                            T.where((ax2_0 * T.int64(512) + ax2_1) * T.int64(4) + ax2_2 < T.int64(2560))\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(512) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(512) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(1537, 1664)>": {
            "latency(ms)": 0.0323953985092193,
            "config": [
                {
                    "len_tx": 512,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(2)):\n                for ax2_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(2048) + ax2_1 * T.int64(4) + ax2_2)\n                            T.where((ax2_0 * T.int64(512) + ax2_1) * T.int64(4) + ax2_2 < T.int64(2560))\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(512) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(512) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(1665, 1792)>": {
            "latency(ms)": 0.03453945467230444,
            "config": [
                {
                    "len_tx": 512,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(2)):\n                for ax2_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(2048) + ax2_1 * T.int64(4) + ax2_2)\n                            T.where((ax2_0 * T.int64(512) + ax2_1) * T.int64(4) + ax2_2 < T.int64(2560))\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(512) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(512) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(1793, 1920)>": {
            "latency(ms)": 0.037021541822323464,
            "config": [
                {
                    "len_tx": 512,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(2)):\n                for ax2_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(2048) + ax2_1 * T.int64(4) + ax2_2)\n                            T.where((ax2_0 * T.int64(512) + ax2_1) * T.int64(4) + ax2_2 < T.int64(2560))\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(512) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(512) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(1921, 2048)>": {
            "latency(ms)": 0.03953028095238096,
            "config": [
                {
                    "len_tx": 512,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(2)):\n                for ax2_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(2048) + ax2_1 * T.int64(4) + ax2_2)\n                            T.where((ax2_0 * T.int64(512) + ax2_1) * T.int64(4) + ax2_2 < T.int64(2560))\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(512) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(512) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(2049, 2176)>": {
            "latency(ms)": 0.04184919386503068,
            "config": [
                {
                    "len_tx": 160,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(4)):\n                for ax2_1 in T.thread_binding(T.int64(160), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(640) + ax2_1 * T.int64(4) + ax2_2)\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(160), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(16), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(160) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(160), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(16), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(160) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(2177, 2304)>": {
            "latency(ms)": 0.04445346688741721,
            "config": [
                {
                    "len_tx": 512,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(2)):\n                for ax2_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(2048) + ax2_1 * T.int64(4) + ax2_2)\n                            T.where((ax2_0 * T.int64(512) + ax2_1) * T.int64(4) + ax2_2 < T.int64(2560))\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(512) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(512) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(2305, 2432)>": {
            "latency(ms)": 0.046812772773681226,
            "config": [
                {
                    "len_tx": 320,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(2)):\n                for ax2_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(1280) + ax2_1 * T.int64(4) + ax2_2)\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(8), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(320) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(8), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(320) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(2433, 2560)>": {
            "latency(ms)": 0.0490371118902439,
            "config": [
                {
                    "len_tx": 320,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(2)):\n                for ax2_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(1280) + ax2_1 * T.int64(4) + ax2_2)\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(8), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(320) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(8), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(320) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(2561, 2688)>": {
            "latency(ms)": 0.051339635865504364,
            "config": [
                {
                    "len_tx": 320,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(2)):\n                for ax2_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(1280) + ax2_1 * T.int64(4) + ax2_2)\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(8), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(320) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(320), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(8), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(320) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(2689, 2816)>": {
            "latency(ms)": 0.053631999347258485,
            "config": [
                {
                    "len_tx": 192,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(4)):\n                for ax2_1 in T.thread_binding(T.int64(192), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(768) + ax2_1 * T.int64(4) + ax2_2)\n                            T.where((ax2_0 * T.int64(192) + ax2_1) * T.int64(4) + ax2_2 < T.int64(2560))\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(192), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(14), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(192) + ax1_fused_1)\n                            T.where(ax1_fused_0 * T.int64(192) + ax1_fused_1 < T.int64(2560))\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(192), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(14), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(192) + ax1_1)\n                        T.where(ax1_0 * T.int64(192) + ax1_1 < T.int64(2560))\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(2817, 2944)>": {
            "latency(ms)": 0.05586216101928374,
            "config": [
                {
                    "len_tx": 512,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(2)):\n                for ax2_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(2048) + ax2_1 * T.int64(4) + ax2_2)\n                            T.where((ax2_0 * T.int64(512) + ax2_1) * T.int64(4) + ax2_2 < T.int64(2560))\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(512) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(512) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(2945, 3072)>": {
            "latency(ms)": 0.05823821495327103,
            "config": [
                {
                    "len_tx": 512,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(2)):\n                for ax2_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(2048) + ax2_1 * T.int64(4) + ax2_2)\n                            T.where((ax2_0 * T.int64(512) + ax2_1) * T.int64(4) + ax2_2 < T.int64(2560))\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(512) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(512) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(3073, 3200)>": {
            "latency(ms)": 0.06052765287528007,
            "config": [
                {
                    "len_tx": 512,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(2)):\n                for ax2_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(2048) + ax2_1 * T.int64(4) + ax2_2)\n                            T.where((ax2_0 * T.int64(512) + ax2_1) * T.int64(4) + ax2_2 < T.int64(2560))\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(512) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(512) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(3201, 3328)>": {
            "latency(ms)": 0.06289588845855926,
            "config": [
                {
                    "len_tx": 512,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(2)):\n                for ax2_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(2048) + ax2_1 * T.int64(4) + ax2_2)\n                            T.where((ax2_0 * T.int64(512) + ax2_1) * T.int64(4) + ax2_2 < T.int64(2560))\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(512) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(512) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(3329, 3456)>": {
            "latency(ms)": 0.06520505577689242,
            "config": [
                {
                    "len_tx": 512,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(2)):\n                for ax2_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(2048) + ax2_1 * T.int64(4) + ax2_2)\n                            T.where((ax2_0 * T.int64(512) + ax2_1) * T.int64(4) + ax2_2 < T.int64(2560))\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(512) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(512) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(3457, 3584)>": {
            "latency(ms)": 0.06744462603993343,
            "config": [
                {
                    "len_tx": 512,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(2)):\n                for ax2_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(2048) + ax2_1 * T.int64(4) + ax2_2)\n                            T.where((ax2_0 * T.int64(512) + ax2_1) * T.int64(4) + ax2_2 < T.int64(2560))\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(512) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(512) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(3585, 3712)>": {
            "latency(ms)": 0.0696352206632653,
            "config": [
                {
                    "len_tx": 192,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(4)):\n                for ax2_1 in T.thread_binding(T.int64(192), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(768) + ax2_1 * T.int64(4) + ax2_2)\n                            T.where((ax2_0 * T.int64(192) + ax2_1) * T.int64(4) + ax2_2 < T.int64(2560))\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(192), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(14), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(192) + ax1_fused_1)\n                            T.where(ax1_fused_0 * T.int64(192) + ax1_fused_1 < T.int64(2560))\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(192), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(14), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(192) + ax1_1)\n                        T.where(ax1_0 * T.int64(192) + ax1_1 < T.int64(2560))\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(3713, 3840)>": {
            "latency(ms)": 0.07215441975417033,
            "config": [
                {
                    "len_tx": 512,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(2)):\n                for ax2_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(2048) + ax2_1 * T.int64(4) + ax2_2)\n                            T.where((ax2_0 * T.int64(512) + ax2_1) * T.int64(4) + ax2_2 < T.int64(2560))\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(512) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(512) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(3841, 3968)>": {
            "latency(ms)": 0.07439686466302368,
            "config": [
                {
                    "len_tx": 512,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(2)):\n                for ax2_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(2048) + ax2_1 * T.int64(4) + ax2_2)\n                            T.where((ax2_0 * T.int64(512) + ax2_1) * T.int64(4) + ax2_2 < T.int64(2560))\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(512) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(512) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    },
    {
        "fused_layer_norm_cast1_<n: Range(3969, 4096)>": {
            "latency(ms)": 0.07652369525616698,
            "config": [
                {
                    "len_tx": 512,
                    "unroll_depth": 256,
                    "vector_size": 4,
                    "temp_storage": "shared.dyn"
                }
            ],
            "mod": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func(private=True)\n    def main(p_lv6: T.handle, param_1: T.Buffer((T.int64(2560),), \"float32\"), param_2: T.Buffer((T.int64(2560),), \"float32\"), p_output0: T.handle):\n        T.func_attr({\"tir.noalias\": T.bool(True)})\n        n = T.int64()\n        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(2560)))\n        compute_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(2560)), \"float16\")\n        # with T.block(\"root\"):\n        A_red_temp_v0_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        A_red_temp_v1_shared = T.alloc_buffer((T.int64(1), n), scope=\"shared\")\n        lv6_shared_dyn = T.alloc_buffer((T.int64(1), n, T.int64(2560)), scope=\"shared.dyn\")\n        for ax0_fused in T.thread_binding(n, thread=\"blockIdx.x\"):\n            for ax0, ax1, ax2_0 in T.grid(T.int64(1), T.int64(1), T.int64(2)):\n                for ax2_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax2_2 in T.vectorized(T.int64(4)):\n                        with T.block(\"lv6_shared.dyn\"):\n                            v0 = T.axis.spatial(T.int64(1), ax0)\n                            v1 = T.axis.spatial(n, ax0_fused + ax1)\n                            v2 = T.axis.spatial(T.int64(2560), ax2_0 * T.int64(2048) + ax2_1 * T.int64(4) + ax2_2)\n                            T.where((ax2_0 * T.int64(512) + ax2_1) * T.int64(4) + ax2_2 < T.int64(2560))\n                            T.reads(lv6[v0, v1, v2])\n                            T.writes(lv6_shared_dyn[v0, v1, v2])\n                            lv6_shared_dyn[v0, v1, v2] = lv6[v0, v1, v2]\n            for ax0 in range(T.int64(1)):\n                for ax1_fused_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                    for ax1_fused_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                        with T.block(\"A_red_temp\"):\n                            v0 = T.axis.spatial(n, ax0_fused + ax0)\n                            v1 = T.axis.reduce(T.int64(2560), ax1_fused_0 * T.int64(512) + ax1_fused_1)\n                            T.reads(lv6_shared_dyn[T.int64(0), v0, v1])\n                            T.writes(A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0])\n                            with T.init():\n                                A_red_temp_v0_shared[T.int64(0), v0] = T.float32(0)\n                                A_red_temp_v1_shared[T.int64(0), v0] = T.float32(0)\n                            v_A_red_temp_v0: T.float32 = A_red_temp_v0_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1]\n                            v_A_red_temp_v1: T.float32 = A_red_temp_v1_shared[T.int64(0), v0] + lv6_shared_dyn[T.int64(0), v0, v1] * lv6_shared_dyn[T.int64(0), v0, v1]\n                            A_red_temp_v0_shared[T.int64(0), v0] = v_A_red_temp_v0\n                            A_red_temp_v1_shared[T.int64(0), v0] = v_A_red_temp_v1\n            for ax1_1 in T.thread_binding(T.int64(512), thread=\"threadIdx.x\"):\n                for ax1_0 in T.serial(T.int64(5), annotations={\"pragma_auto_unroll_max_step\": 256, \"pragma_unroll_explicit\": 1}):\n                    with T.block(\"compute\"):\n                        v0 = T.axis.spatial(n, ax0_fused)\n                        v1 = T.axis.spatial(T.int64(2560), ax1_0 * T.int64(512) + ax1_1)\n                        T.reads(lv6_shared_dyn[T.int64(0), v0, v1], A_red_temp_v0_shared[T.int64(0), v0], A_red_temp_v1_shared[T.int64(0), v0], param_1[v1], param_2[v1])\n                        T.writes(compute_intermediate[T.int64(0), v0, v1])\n                        compute_intermediate[T.int64(0), v0, v1] = T.Cast(\"float16\", (lv6_shared_dyn[T.int64(0), v0, v1] - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) * T.rsqrt(A_red_temp_v1_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) - A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002) * (A_red_temp_v0_shared[T.int64(0), v0] * T.float32(0.00039062500000000002)) + T.float32(1.0000000000000001e-05)) * param_1[v1] + param_2[v1])"
        }
    }
]